{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bf11f48b4254b5b857c9b52c3b8141e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82c28ce4b8b94141b355a3430ed5a49a",
              "IPY_MODEL_e7d18f86d64b45dcb0026f56f179898b",
              "IPY_MODEL_8f22b1d4541b471f98c186f96e62722d"
            ],
            "layout": "IPY_MODEL_56526c676d374f6daa79dd35b61d3a2c"
          }
        },
        "82c28ce4b8b94141b355a3430ed5a49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cca9c913284ac2bee5ca6bc5a20b62",
            "placeholder": "​",
            "style": "IPY_MODEL_5054a877d5c04787b268c6213bd3df04",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e7d18f86d64b45dcb0026f56f179898b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56aef2d90a22450cadcdc7d3c9303dba",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85f954bb378247588718f056dd549214",
            "value": 366
          }
        },
        "8f22b1d4541b471f98c186f96e62722d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c075294278c4e0f930044ad0c679515",
            "placeholder": "​",
            "style": "IPY_MODEL_bf68d65d651c40a4ae2dd6608d5d6e59",
            "value": " 366/366 [00:00&lt;00:00, 5.30kB/s]"
          }
        },
        "56526c676d374f6daa79dd35b61d3a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34cca9c913284ac2bee5ca6bc5a20b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5054a877d5c04787b268c6213bd3df04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56aef2d90a22450cadcdc7d3c9303dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f954bb378247588718f056dd549214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c075294278c4e0f930044ad0c679515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf68d65d651c40a4ae2dd6608d5d6e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf77e19ed17642efa5acd5067439f9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8626472ca2684a72bfc57dd4fdcd0add",
              "IPY_MODEL_58da7c78bf1a40d6bfc4ac667b0ef42a",
              "IPY_MODEL_a50af8020fe54bce9f7065444ba7aab0"
            ],
            "layout": "IPY_MODEL_1053dd832e3b4d03b29dc925d943b6f1"
          }
        },
        "8626472ca2684a72bfc57dd4fdcd0add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ebc8bb63544fcbbc3ae421f3e4ea2e",
            "placeholder": "​",
            "style": "IPY_MODEL_9f203a21d4b848a08ff49411387f9fd0",
            "value": "vocab.txt: 100%"
          }
        },
        "58da7c78bf1a40d6bfc4ac667b0ef42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8639cfffddf142e4b415a1f7a87f0588",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce79f22768b24a66aba09cfa21984886",
            "value": 231508
          }
        },
        "a50af8020fe54bce9f7065444ba7aab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242cacb1297b41418ea021583f5bbbf0",
            "placeholder": "​",
            "style": "IPY_MODEL_07ed75b6304d41f9afbe9603437c0bb7",
            "value": " 232k/232k [00:00&lt;00:00, 546kB/s]"
          }
        },
        "1053dd832e3b4d03b29dc925d943b6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ebc8bb63544fcbbc3ae421f3e4ea2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f203a21d4b848a08ff49411387f9fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8639cfffddf142e4b415a1f7a87f0588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce79f22768b24a66aba09cfa21984886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "242cacb1297b41418ea021583f5bbbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ed75b6304d41f9afbe9603437c0bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dae479c20fda4b2eb4acb426256176a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de826cf2852c48dfb16d058ca5d9cf28",
              "IPY_MODEL_503f2d09add54b76836ca63b8566caef",
              "IPY_MODEL_a3b3914784e041e7929670f8b85d0291"
            ],
            "layout": "IPY_MODEL_86b30981c57849d591fcecae3931a66b"
          }
        },
        "de826cf2852c48dfb16d058ca5d9cf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cee9895636d4fa6a82e96dcea077d36",
            "placeholder": "​",
            "style": "IPY_MODEL_7341139b232b4ea5859dafa60c432137",
            "value": "tokenizer.json: 100%"
          }
        },
        "503f2d09add54b76836ca63b8566caef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca07eb89fd542ccb4489f8ff0334cab",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0c539c8fa2842609b3a7aa228eb889a",
            "value": 711396
          }
        },
        "a3b3914784e041e7929670f8b85d0291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20729c0a18e47c3a7a6b5de3eaa6da9",
            "placeholder": "​",
            "style": "IPY_MODEL_f145ddd828f44c37a1537e50cbbdb642",
            "value": " 711k/711k [00:00&lt;00:00, 1.11MB/s]"
          }
        },
        "86b30981c57849d591fcecae3931a66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cee9895636d4fa6a82e96dcea077d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7341139b232b4ea5859dafa60c432137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ca07eb89fd542ccb4489f8ff0334cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c539c8fa2842609b3a7aa228eb889a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d20729c0a18e47c3a7a6b5de3eaa6da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f145ddd828f44c37a1537e50cbbdb642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b40b44d1c0848189299387cddbbac9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75bb7d5f798444baa91b3b7d5052a575",
              "IPY_MODEL_192d0f2cc29b430e800fee96888c0a66",
              "IPY_MODEL_faf66846ef70470796a16d7610aa2358"
            ],
            "layout": "IPY_MODEL_d6513043c7a24392bfe6f53867fe7825"
          }
        },
        "75bb7d5f798444baa91b3b7d5052a575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9cab01bb674a3d849fc7de7b01890a",
            "placeholder": "​",
            "style": "IPY_MODEL_1c706894acea4635acd9a501701185a4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "192d0f2cc29b430e800fee96888c0a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbb5c34a1cd43aaa4c8a12447a77ee9",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c628495684c84a868a26ec8b5484bbda",
            "value": 125
          }
        },
        "faf66846ef70470796a16d7610aa2358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6703ba752448c2b2d6ceb96efe51a0",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa67665142f42a98bf5c1c5ba06f063",
            "value": " 125/125 [00:00&lt;00:00, 3.15kB/s]"
          }
        },
        "d6513043c7a24392bfe6f53867fe7825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9cab01bb674a3d849fc7de7b01890a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c706894acea4635acd9a501701185a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bbb5c34a1cd43aaa4c8a12447a77ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c628495684c84a868a26ec8b5484bbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef6703ba752448c2b2d6ceb96efe51a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa67665142f42a98bf5c1c5ba06f063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02445f7cd42449189773961901a6c285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50de39be53b74c2c99cbbfa7ae1ed68b",
              "IPY_MODEL_25306f09d0db4cd0911c9f1bf888c07d",
              "IPY_MODEL_f694df4d02b64418a2e94133f93b622a"
            ],
            "layout": "IPY_MODEL_902596b0817b4f2d8cb670aa38df1b57"
          }
        },
        "50de39be53b74c2c99cbbfa7ae1ed68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88e9fed25e7c4317954188c9acf526cd",
            "placeholder": "​",
            "style": "IPY_MODEL_30c72d5ad6f64ec987939de4859f94f8",
            "value": "config.json: 100%"
          }
        },
        "25306f09d0db4cd0911c9f1bf888c07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffd484b095f48ee947dd1b0244b3134",
            "max": 779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d26fc68e8fd4e35a6c9cbed2f412805",
            "value": 779
          }
        },
        "f694df4d02b64418a2e94133f93b622a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce01aaffb9e24b3485910839e525c914",
            "placeholder": "​",
            "style": "IPY_MODEL_a046055adb044efe952aa8ebb327b87a",
            "value": " 779/779 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "902596b0817b4f2d8cb670aa38df1b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e9fed25e7c4317954188c9acf526cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c72d5ad6f64ec987939de4859f94f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ffd484b095f48ee947dd1b0244b3134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d26fc68e8fd4e35a6c9cbed2f412805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce01aaffb9e24b3485910839e525c914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a046055adb044efe952aa8ebb327b87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5f71d85a5e64c58bdcb4582f0053ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33672eec10af48efa6a8efcb0c4e69be",
              "IPY_MODEL_5e7cb2ae37804c5da8d9ff267808735a",
              "IPY_MODEL_aa74b45e35fa44a4a675b89e1a0953cc"
            ],
            "layout": "IPY_MODEL_27b18ab7cb5d4d60a1d6037227331170"
          }
        },
        "33672eec10af48efa6a8efcb0c4e69be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59729c7f117f4d99a0f8cd6dcd0a4b0c",
            "placeholder": "​",
            "style": "IPY_MODEL_0dadcac982e34b4d8c361c003dace008",
            "value": "model.safetensors: 100%"
          }
        },
        "5e7cb2ae37804c5da8d9ff267808735a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b170fbc9b6497395e461f073798775",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03908d8946954f8ab5cd7f862ac6169c",
            "value": 1340616616
          }
        },
        "aa74b45e35fa44a4a675b89e1a0953cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0bcab480e44433a3c1af6ce164577e",
            "placeholder": "​",
            "style": "IPY_MODEL_13d007b5bb8d4c108194f57a34c291dd",
            "value": " 1.34G/1.34G [00:11&lt;00:00, 199MB/s]"
          }
        },
        "27b18ab7cb5d4d60a1d6037227331170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59729c7f117f4d99a0f8cd6dcd0a4b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dadcac982e34b4d8c361c003dace008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b170fbc9b6497395e461f073798775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03908d8946954f8ab5cd7f862ac6169c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b0bcab480e44433a3c1af6ce164577e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d007b5bb8d4c108194f57a34c291dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "4bf11f48b4254b5b857c9b52c3b8141e",
            "82c28ce4b8b94141b355a3430ed5a49a",
            "e7d18f86d64b45dcb0026f56f179898b",
            "8f22b1d4541b471f98c186f96e62722d",
            "56526c676d374f6daa79dd35b61d3a2c",
            "34cca9c913284ac2bee5ca6bc5a20b62",
            "5054a877d5c04787b268c6213bd3df04",
            "56aef2d90a22450cadcdc7d3c9303dba",
            "85f954bb378247588718f056dd549214",
            "8c075294278c4e0f930044ad0c679515",
            "bf68d65d651c40a4ae2dd6608d5d6e59",
            "bf77e19ed17642efa5acd5067439f9aa",
            "8626472ca2684a72bfc57dd4fdcd0add",
            "58da7c78bf1a40d6bfc4ac667b0ef42a",
            "a50af8020fe54bce9f7065444ba7aab0",
            "1053dd832e3b4d03b29dc925d943b6f1",
            "22ebc8bb63544fcbbc3ae421f3e4ea2e",
            "9f203a21d4b848a08ff49411387f9fd0",
            "8639cfffddf142e4b415a1f7a87f0588",
            "ce79f22768b24a66aba09cfa21984886",
            "242cacb1297b41418ea021583f5bbbf0",
            "07ed75b6304d41f9afbe9603437c0bb7",
            "dae479c20fda4b2eb4acb426256176a2",
            "de826cf2852c48dfb16d058ca5d9cf28",
            "503f2d09add54b76836ca63b8566caef",
            "a3b3914784e041e7929670f8b85d0291",
            "86b30981c57849d591fcecae3931a66b",
            "6cee9895636d4fa6a82e96dcea077d36",
            "7341139b232b4ea5859dafa60c432137",
            "6ca07eb89fd542ccb4489f8ff0334cab",
            "a0c539c8fa2842609b3a7aa228eb889a",
            "d20729c0a18e47c3a7a6b5de3eaa6da9",
            "f145ddd828f44c37a1537e50cbbdb642",
            "1b40b44d1c0848189299387cddbbac9e",
            "75bb7d5f798444baa91b3b7d5052a575",
            "192d0f2cc29b430e800fee96888c0a66",
            "faf66846ef70470796a16d7610aa2358",
            "d6513043c7a24392bfe6f53867fe7825",
            "ba9cab01bb674a3d849fc7de7b01890a",
            "1c706894acea4635acd9a501701185a4",
            "1bbb5c34a1cd43aaa4c8a12447a77ee9",
            "c628495684c84a868a26ec8b5484bbda",
            "ef6703ba752448c2b2d6ceb96efe51a0",
            "3aa67665142f42a98bf5c1c5ba06f063",
            "02445f7cd42449189773961901a6c285",
            "50de39be53b74c2c99cbbfa7ae1ed68b",
            "25306f09d0db4cd0911c9f1bf888c07d",
            "f694df4d02b64418a2e94133f93b622a",
            "902596b0817b4f2d8cb670aa38df1b57",
            "88e9fed25e7c4317954188c9acf526cd",
            "30c72d5ad6f64ec987939de4859f94f8",
            "3ffd484b095f48ee947dd1b0244b3134",
            "8d26fc68e8fd4e35a6c9cbed2f412805",
            "ce01aaffb9e24b3485910839e525c914",
            "a046055adb044efe952aa8ebb327b87a",
            "f5f71d85a5e64c58bdcb4582f0053ce6",
            "33672eec10af48efa6a8efcb0c4e69be",
            "5e7cb2ae37804c5da8d9ff267808735a",
            "aa74b45e35fa44a4a675b89e1a0953cc",
            "27b18ab7cb5d4d60a1d6037227331170",
            "59729c7f117f4d99a0f8cd6dcd0a4b0c",
            "0dadcac982e34b4d8c361c003dace008",
            "e5b170fbc9b6497395e461f073798775",
            "03908d8946954f8ab5cd7f862ac6169c",
            "0b0bcab480e44433a3c1af6ce164577e",
            "13d007b5bb8d4c108194f57a34c291dd"
          ]
        },
        "id": "78e3BkkJnxW-",
        "outputId": "a84b3499-9d25-4b33-ba78-7276c1f5a9df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- Float tensor set --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bf11f48b4254b5b857c9b52c3b8141e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf77e19ed17642efa5acd5067439f9aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae479c20fda4b2eb4acb426256176a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b40b44d1c0848189299387cddbbac9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02445f7cd42449189773961901a6c285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5f71d85a5e64c58bdcb4582f0053ce6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    print('----------- Float tensor set --------------')\n",
        "else:\n",
        "    print('---------------------- No CUDA -----------------')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_name = \"BAAI/bge-large-en-v1.5\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.embeddings(input_ids=torch.tensor([[ 101, 3894, 2003, 2613,  102]]), token_type_ids = torch.tensor([[0, 0, 0, 0, 0]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U7vMQQrTm5J",
        "outputId": "3f92326f-3f03-465c-aab4-49c6afd69c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0579, -0.1454, -0.1149,  ..., -0.0850, -0.0970,  0.0441],\n",
            "         [-1.0723, -0.3718,  1.0997,  ..., -1.1722,  0.3788,  0.6327],\n",
            "         [ 0.2190,  0.1230, -0.4146,  ...,  0.5126, -0.3004,  0.8545],\n",
            "         [-0.2538,  0.9347,  0.9419,  ...,  0.3180,  1.0190,  0.1344],\n",
            "         [-0.0852,  0.1868, -0.1751,  ...,  0.0075,  0.3693,  0.0385]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# for i in tqdm(range(20_000)):\n",
        "#     for j in range(20_000):\n",
        "#         if i == j: continue\n",
        "#         model.embeddings(input_ids=torch.tensor([[ 101, i, j, 1,  102]]), token_type_ids = torch.tensor([[0, 0, 0, 0, 0]]))\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Pre-create the fixed tensor components to avoid repetition\n",
        "token_type_ids = torch.tensor([[0, 0, 0, 0, 0]]).to('cuda')\n",
        "\n",
        "# Function to generate input batches\n",
        "def generate_input_batches(batch_size=64, vocab_size=20_000):\n",
        "    input_ids = []\n",
        "    for i in range(vocab_size):\n",
        "        for j in range(vocab_size):  # Skip j <= i to avoid checking i == j\n",
        "            input_ids.append([101, i, j, 1, 102])\n",
        "\n",
        "        # Yield the batch when it's filled to avoid storing everything at once\n",
        "        if len(input_ids) >= batch_size:\n",
        "            yield torch.tensor(input_ids).to('cuda')\n",
        "            input_ids = []  # Reset the batch\n",
        "\n",
        "    # Yield any remaining input_ids that didn't fill a full batch\n",
        "    if input_ids:\n",
        "        yield torch.tensor(input_ids)\n",
        "\n",
        "# Set up the DataLoader to process input batches\n",
        "batch_size = 100_000  # Modify this based on available memory\n",
        "input_batches = generate_input_batches(batch_size=batch_size)\n",
        "\n",
        "# Now iterate over the batches and feed them to the model\n",
        "for input_batch in tqdm(input_batches, desc=\"Processing batches\"):\n",
        "    # Assuming the model can handle batch processing\n",
        "    input_batch = input_batch.unsqueeze(1)  # Add batch dimension\n",
        "    model.embeddings(input_ids=input_batch, token_type_ids=token_type_ids)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uFacPvl87lH",
        "outputId": "0e5554f0-f9a2-4035-f753-6333a5db49b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 4000it [19:42,  3.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetText = 'magic is real'\n",
        "print(tokenizer(targetText, return_tensors='pt'))\n",
        "outputs = model(**tokenizer(targetText, return_tensors='pt'), output_hidden_states=True)\n",
        "target_embedding = outputs.pooler_output[0]\n",
        "print(target_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMMA90GRn8V_",
        "outputId": "df040fca-226f-4f09-8665-a428262d4552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 3894, 2003, 2613,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
            "tensor([-0.9450, -0.8097, -0.8362,  ...,  0.4859,  0.9817, -0.8716],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(targetText, return_tensors='pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KyNtE328ppr",
        "outputId": "f15f78e1-5305-411a-c9c9-6aa1912cf125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 3894, 2003, 2613,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.pooler_output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPnyYTFuMCgn",
        "outputId": "a77e793a-ac77-4b6f-8e01-187a01c72cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(outputs.hidden_states)):\n",
        "    print(outputs.hidden_states[i])"
      ],
      "metadata": {
        "id": "c0NR_EJxobja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.pooler_output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcAZOlucozDf",
        "outputId": "e6724698-42dd-4562-c94c-96a80dfea041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9450, -0.8097, -0.8362,  ...,  0.4859,  0.9817, -0.8716],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.pooler(outputs.hidden_states[-1])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxK_W4RQpGUw",
        "outputId": "e96cdd4d-5fdd-401c-90da-5435735ebf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9450, -0.8097, -0.8362,  ...,  0.4859,  0.9817, -0.8716],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "  # Normalize the embeddings\n",
        "  embedding1_normalized = F.normalize(embedding1, p=2, dim=0)\n",
        "  embedding2_normalized = F.normalize(embedding2, p=2, dim=0)\n",
        "\n",
        "  # Calculate the dot product\n",
        "  dot_product = torch.dot(embedding1_normalized, embedding2_normalized)\n",
        "\n",
        "  return dot_product.item()\n",
        "\n",
        "text1 = 'magic is real'\n",
        "text2 = 'magic are real'\n",
        "print(tokenizer(text1, return_tensors='pt'))\n",
        "print(tokenizer(text2, return_tensors='pt'))\n",
        "cosine_similarity(model(**tokenizer(text1, return_tensors='pt'), output_hidden_states=True).pooler_output[0], model(**tokenizer(text2, return_tensors='pt'), output_hidden_states=True).pooler_output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eemX_TS3ooXE",
        "outputId": "46bc67ac-71e7-4567-a480-4db70ada377a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 3894, 2003, 2613,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
            "{'input_ids': tensor([[ 101, 3894, 2024, 2613,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9960455894470215"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosineSimilarities = []\n",
        "\n",
        "for i in range(len(outputs.hidden_states)):\n",
        "    hiddenStateSimilarity = []\n",
        "    embeddingI = model.pooler(outputs.hidden_states[i])[0]\n",
        "    for j in range(len(outputs.hidden_states)):\n",
        "        embeddingJ = model.pooler(outputs.hidden_states[j])[0]\n",
        "        hiddenStateSimilarity.append(round(cosine_similarity(embeddingI, embeddingJ), 2))\n",
        "    cosineSimilarities.append(hiddenStateSimilarity)"
      ],
      "metadata": {
        "id": "45MtGwbQpS5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cosineSimilarities)):\n",
        "    print(f'{cosineSimilarities[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjxDCR7Zqlgp",
        "outputId": "43a30e7e-6a8a-42a2-e054-132ffeac6d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 0.85, 0.84, 0.84, 0.85, 0.78, 0.59, 0.35, -0.0, -0.06, 0.01, 0.17, -0.01, 0.07, -0.08, 0.08, 0.1, -0.15, -0.17, -0.03, -0.01, 0.1, 0.11, 0.19, 0.16]\n",
            "[0.85, 1.0, 1.0, 0.99, 0.99, 0.93, 0.7, 0.36, -0.05, -0.09, 0.05, 0.29, 0.07, 0.18, -0.01, 0.24, 0.26, -0.12, -0.2, -0.01, 0.01, 0.16, 0.17, 0.26, 0.27]\n",
            "[0.84, 1.0, 1.0, 1.0, 0.99, 0.93, 0.71, 0.36, -0.07, -0.11, 0.04, 0.29, 0.06, 0.18, -0.01, 0.26, 0.29, -0.1, -0.19, 0.01, 0.04, 0.19, 0.2, 0.29, 0.3]\n",
            "[0.84, 0.99, 1.0, 1.0, 1.0, 0.93, 0.7, 0.35, -0.08, -0.11, 0.03, 0.28, 0.05, 0.15, -0.03, 0.25, 0.28, -0.1, -0.18, 0.02, 0.04, 0.2, 0.21, 0.3, 0.3]\n",
            "[0.85, 0.99, 0.99, 1.0, 1.0, 0.95, 0.74, 0.38, -0.09, -0.13, 0.02, 0.28, 0.05, 0.15, -0.04, 0.26, 0.29, -0.09, -0.18, 0.04, 0.06, 0.22, 0.23, 0.33, 0.33]\n",
            "[0.78, 0.93, 0.93, 0.93, 0.95, 1.0, 0.91, 0.58, -0.04, -0.1, 0.08, 0.39, 0.12, 0.2, -0.02, 0.32, 0.37, -0.08, -0.19, 0.08, 0.1, 0.31, 0.31, 0.42, 0.45]\n",
            "[0.59, 0.7, 0.71, 0.7, 0.74, 0.91, 1.0, 0.79, 0.07, -0.0, 0.18, 0.49, 0.21, 0.25, 0.01, 0.33, 0.39, -0.06, -0.17, 0.14, 0.16, 0.39, 0.38, 0.48, 0.52]\n",
            "[0.35, 0.36, 0.36, 0.35, 0.38, 0.58, 0.79, 1.0, 0.63, 0.55, 0.64, 0.75, 0.59, 0.54, 0.33, 0.23, 0.25, -0.04, -0.11, 0.08, 0.1, 0.28, 0.25, 0.29, 0.33]\n",
            "[-0.0, -0.05, -0.07, -0.08, -0.09, -0.04, 0.07, 0.63, 1.0, 0.98, 0.91, 0.7, 0.8, 0.69, 0.64, 0.06, -0.01, 0.02, 0.06, -0.06, -0.03, -0.03, -0.07, -0.13, -0.16]\n",
            "[-0.06, -0.09, -0.11, -0.11, -0.13, -0.1, -0.0, 0.55, 0.98, 1.0, 0.94, 0.72, 0.84, 0.72, 0.7, 0.1, 0.03, 0.06, 0.1, -0.05, -0.02, -0.03, -0.07, -0.14, -0.18]\n",
            "[0.01, 0.05, 0.04, 0.03, 0.02, 0.08, 0.18, 0.64, 0.91, 0.94, 1.0, 0.87, 0.92, 0.85, 0.76, 0.3, 0.23, 0.17, 0.13, 0.05, 0.05, 0.08, 0.04, -0.0, 0.01]\n",
            "[0.17, 0.29, 0.29, 0.28, 0.28, 0.39, 0.49, 0.75, 0.7, 0.72, 0.87, 1.0, 0.9, 0.87, 0.7, 0.52, 0.48, 0.24, 0.16, 0.23, 0.23, 0.34, 0.31, 0.31, 0.32]\n",
            "[-0.01, 0.07, 0.06, 0.05, 0.05, 0.12, 0.21, 0.59, 0.8, 0.84, 0.92, 0.9, 1.0, 0.93, 0.87, 0.48, 0.38, 0.25, 0.23, 0.11, 0.1, 0.13, 0.08, 0.03, 0.02]\n",
            "[0.07, 0.18, 0.18, 0.15, 0.15, 0.2, 0.25, 0.54, 0.69, 0.72, 0.85, 0.87, 0.93, 1.0, 0.9, 0.61, 0.5, 0.33, 0.29, 0.18, 0.16, 0.16, 0.11, 0.08, 0.07]\n",
            "[-0.08, -0.01, -0.01, -0.03, -0.04, -0.02, 0.01, 0.33, 0.64, 0.7, 0.76, 0.7, 0.87, 0.9, 1.0, 0.63, 0.5, 0.44, 0.44, 0.2, 0.16, 0.09, 0.02, -0.07, -0.11]\n",
            "[0.08, 0.24, 0.26, 0.25, 0.26, 0.32, 0.33, 0.23, 0.06, 0.1, 0.3, 0.52, 0.48, 0.61, 0.63, 1.0, 0.96, 0.75, 0.65, 0.61, 0.51, 0.5, 0.44, 0.39, 0.39]\n",
            "[0.1, 0.26, 0.29, 0.28, 0.29, 0.37, 0.39, 0.25, -0.01, 0.03, 0.23, 0.48, 0.38, 0.5, 0.5, 0.96, 1.0, 0.8, 0.67, 0.7, 0.58, 0.59, 0.54, 0.51, 0.52]\n",
            "[-0.15, -0.12, -0.1, -0.1, -0.09, -0.08, -0.06, -0.04, 0.02, 0.06, 0.17, 0.24, 0.25, 0.33, 0.44, 0.75, 0.8, 1.0, 0.91, 0.83, 0.68, 0.54, 0.5, 0.41, 0.4]\n",
            "[-0.17, -0.2, -0.19, -0.18, -0.18, -0.19, -0.17, -0.11, 0.06, 0.1, 0.13, 0.16, 0.23, 0.29, 0.44, 0.65, 0.67, 0.91, 1.0, 0.82, 0.72, 0.53, 0.48, 0.35, 0.23]\n",
            "[-0.03, -0.01, 0.01, 0.02, 0.04, 0.08, 0.14, 0.08, -0.06, -0.05, 0.05, 0.23, 0.11, 0.18, 0.2, 0.61, 0.7, 0.83, 0.82, 1.0, 0.92, 0.82, 0.79, 0.71, 0.6]\n",
            "[-0.01, 0.01, 0.04, 0.04, 0.06, 0.1, 0.16, 0.1, -0.03, -0.02, 0.05, 0.23, 0.1, 0.16, 0.16, 0.51, 0.58, 0.68, 0.72, 0.92, 1.0, 0.92, 0.9, 0.79, 0.58]\n",
            "[0.1, 0.16, 0.19, 0.2, 0.22, 0.31, 0.39, 0.28, -0.03, -0.03, 0.08, 0.34, 0.13, 0.16, 0.09, 0.5, 0.59, 0.54, 0.53, 0.82, 0.92, 1.0, 0.98, 0.93, 0.73]\n",
            "[0.11, 0.17, 0.2, 0.21, 0.23, 0.31, 0.38, 0.25, -0.07, -0.07, 0.04, 0.31, 0.08, 0.11, 0.02, 0.44, 0.54, 0.5, 0.48, 0.79, 0.9, 0.98, 1.0, 0.96, 0.77]\n",
            "[0.19, 0.26, 0.29, 0.3, 0.33, 0.42, 0.48, 0.29, -0.13, -0.14, -0.0, 0.31, 0.03, 0.08, -0.07, 0.39, 0.51, 0.41, 0.35, 0.71, 0.79, 0.93, 0.96, 1.0, 0.86]\n",
            "[0.16, 0.27, 0.3, 0.3, 0.33, 0.45, 0.52, 0.33, -0.16, -0.18, 0.01, 0.32, 0.02, 0.07, -0.11, 0.39, 0.52, 0.4, 0.23, 0.6, 0.58, 0.73, 0.77, 0.86, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_all_possible_inputs(y, W, b):\n",
        "    \"\"\"\n",
        "    Find all possible inputs x that satisfy y = tanh(Wx + b)\n",
        "\n",
        "    Parameters:\n",
        "    y: target output vector (must have all elements between -1 and 1)\n",
        "    W: weight matrix\n",
        "    b: bias vector\n",
        "\n",
        "    Returns:\n",
        "    function that generates solutions based on input z\n",
        "    \"\"\"\n",
        "    # Check if y is valid (all elements between -1 and 1)\n",
        "    if not np.all(np.abs(y) < 1):\n",
        "        raise ValueError(\"All elements of y must be between -1 and 1\")\n",
        "\n",
        "    # Step 1: Apply arctanh\n",
        "    arctanh_y = np.arctanh(y)\n",
        "\n",
        "    # Step 2: Subtract bias\n",
        "    target = arctanh_y - b\n",
        "\n",
        "    # Step 3: Find pseudoinverse of W\n",
        "    W_pinv = np.linalg.pinv(W)\n",
        "\n",
        "    # Create nullspace projection matrix\n",
        "    I = np.eye(W.shape[1])\n",
        "    nullspace_proj = I - W_pinv @ W\n",
        "\n",
        "    # Return function that generates solutions for any z\n",
        "    def solution_generator(z):\n",
        "        particular_solution = W_pinv @ target\n",
        "        nullspace_component = nullspace_proj @ z\n",
        "        print(\"Nullspace component magnitude:\", np.linalg.norm(nullspace_proj @ z))\n",
        "        print(\"Particular solution magnitude:\", np.linalg.norm(particular_solution))\n",
        "        return particular_solution + nullspace_component\n",
        "\n",
        "    return solution_generator\n",
        "\n",
        "# Create sample data\n",
        "n = 1024  # Using small dimension for example\n",
        "W = model.pooler.dense.weight.cpu().detach().clone().numpy()\n",
        "b = model.pooler.dense.bias.cpu().detach().clone().numpy()\n",
        "x_original = outputs.hidden_states[24][0][0].cpu().clone().detach().numpy()\n",
        "y = outputs.pooler_output[0].cpu().clone().detach().numpy()\n",
        "\n",
        "# Find solution generator\n",
        "solution_gen = find_all_possible_inputs(y, W, b)\n",
        "\n",
        "# Generate some solutions\n",
        "z = np.random.randn(n)\n",
        "x_solution = solution_gen(z)\n",
        "\n",
        "# Verify solution\n",
        "y_reconstructed = np.tanh(W @ x_solution + b)\n",
        "print(\"Original y:\", y)\n",
        "print(\"Reconstructed y:\", y_reconstructed)\n",
        "print(\"Original x:\", x_original)\n",
        "print(\"Reconstructed x:\", x_solution)\n",
        "print(\"Difference in input:\", cosine_similarity(torch.tensor(outputs.hidden_states[24][0][0].clone().detach(), dtype=torch.float32),\n",
        "                                                torch.tensor(x_solution, dtype=torch.float32)))\n",
        "print(\"Difference in output:\", cosine_similarity(torch.tensor(y, dtype=torch.float32), torch.tensor(y_reconstructed, dtype=torch.float32)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ5HR1DuLonW",
        "outputId": "38fbf086-ecea-41f6-b0af-e0a458836f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nullspace component magnitude: 0.0013127521677299607\n",
            "Particular solution magnitude: 16.7591\n",
            "Original y: [-0.94499    -0.8097365  -0.83618635 ...  0.48591825  0.9817478\n",
            " -0.8716495 ]\n",
            "Reconstructed y: [-0.94498924 -0.80972441 -0.83615186 ...  0.48591111  0.98174978\n",
            " -0.87165019]\n",
            "Original x: [ 0.35757935  0.3042189   0.56853807 ... -0.26189774  0.37367082\n",
            "  0.65639853]\n",
            "Reconstructed x: [ 0.35779906  0.30413393  0.56839237 ... -0.26174653  0.37360273\n",
            "  0.65654937]\n",
            "Difference in input: 0.9999998807907104\n",
            "Difference in output: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-7715d554ad09>:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(\"Difference in input:\", cosine_similarity(torch.tensor(outputs.hidden_states[24][0][0].clone().detach(), dtype=torch.float32),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_possible_encoder_inputs(output, layer_params, prev_layer_output=None):\n",
        "    \"\"\"\n",
        "    Find possible inputs that could have produced the given output through a BERT encoder layer\n",
        "\n",
        "    Parameters:\n",
        "    output: target output tensor from the layer\n",
        "    layer_params: dict containing weight matrices and biases:\n",
        "        - attention_qkv: weights for query, key, value projections\n",
        "        - attention_output: weights for attention output projection\n",
        "        - intermediate: weights for intermediate dense layer\n",
        "        - output: weights for output dense layer\n",
        "        - layernorm1: first LayerNorm parameters\n",
        "        - layernorm2: second LayerNorm parameters\n",
        "    prev_layer_output: optional output from previous layer (for attention computation)\n",
        "\n",
        "    Returns:\n",
        "    function that generates possible input solutions\n",
        "    \"\"\"\n",
        "    def reverse_layer_norm(normalized_output, gamma, beta, epsilon=1e-12):\n",
        "        # Approximate inverse of layer normalization\n",
        "        mean = beta[None, :]  # Shape: [1, 1024] to broadcast with [5, 1024]\n",
        "        var = (gamma[None, :] ** 2) - epsilon\n",
        "        return normalized_output * np.sqrt(var) + mean\n",
        "\n",
        "    def reverse_gelu(y):\n",
        "        # Simpler, more stable GELU inverse approximation\n",
        "        # Add small epsilon to prevent division by zero\n",
        "        eps = 1e-6\n",
        "\n",
        "        def gelu_forward(x):\n",
        "            return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * x**3)))\n",
        "\n",
        "        def newton_step(x):\n",
        "            gelu = gelu_forward(x)\n",
        "            # Clip to prevent division by zero\n",
        "            x_safe = np.clip(x, -100, 100)\n",
        "            grad = 0.5 * (1 + np.tanh(np.sqrt(2/np.pi) * (x_safe + 0.044715 * x_safe**3)))\n",
        "            grad = np.clip(grad, eps, 1.0)  # Ensure gradient is never zero\n",
        "            return x - (gelu - y) / grad\n",
        "\n",
        "        x = y  # Initial guess\n",
        "        for _ in range(3):  # Fewer iterations for stability\n",
        "            x = np.clip(newton_step(x), -100, 100)  # Clip values to prevent overflow\n",
        "        return x\n",
        "\n",
        "    def find_attention_inputs(target_attention_output, qkv_weights, output_weights, num_heads=16):\n",
        "        W_o = output_weights['weight']\n",
        "        b_o = output_weights['bias']\n",
        "        W_o_pinv = np.linalg.pinv(W_o)\n",
        "\n",
        "        # Get dimensions\n",
        "        seq_length = target_attention_output.shape[0]\n",
        "        hidden_size = target_attention_output.shape[1]\n",
        "        head_size = hidden_size // num_heads\n",
        "\n",
        "        def attention_solution_generator(z):\n",
        "            # Instead of trying to invert the full attention mechanism,\n",
        "            # let's just try to find a vector that produces the right output\n",
        "            target = target_attention_output - b_o[None, :]  # Remove bias\n",
        "\n",
        "            # Use pseudo-inverse to find a particular solution\n",
        "            particular = (W_o_pinv @ target.T).T\n",
        "\n",
        "            # Add a small perturbation from the null space\n",
        "            nullspace = np.eye(W_o.shape[1]) - W_o_pinv @ W_o\n",
        "            z_scaled = z * 0.1  # Scale down the random component\n",
        "            solution = particular + (nullspace @ z_scaled.T).T\n",
        "\n",
        "            return solution\n",
        "\n",
        "        return attention_solution_generator\n",
        "\n",
        "    def solution_generator(z_attention, z_intermediate, temperature=1.0):\n",
        "        # Reverse the transformations in reverse order\n",
        "\n",
        "        # 1. Reverse the final layer norm\n",
        "        prenorm2 = reverse_layer_norm(\n",
        "            output,\n",
        "            layer_params['layernorm2']['gamma'],\n",
        "            layer_params['layernorm2']['beta']\n",
        "        )\n",
        "\n",
        "        # 2. Reverse the residual connection from the intermediate layer\n",
        "        intermediate_output = prenorm2 - output  # Remove residual\n",
        "\n",
        "        # 3. Reverse the output dense layer\n",
        "        W_out = layer_params['output']['weight']\n",
        "        b_out = layer_params['output']['bias']\n",
        "        intermediate_hidden = np.linalg.pinv(W_out) @ intermediate_output.T  # NOT USING BIAS?\n",
        "        intermediate_hidden = intermediate_hidden.T  # Back to [5, 4096]\n",
        "\n",
        "        # 4. Approximate inverse of GELU\n",
        "        pre_gelu = reverse_gelu(intermediate_hidden)\n",
        "\n",
        "        # 5. Reverse the intermediate dense layer\n",
        "        W_int = layer_params['intermediate']['weight']\n",
        "        b_int = layer_params['intermediate']['bias']\n",
        "        pre_gelu = pre_gelu.T  # Shape becomes (4096, 5)\n",
        "        b_int = b_int[:, None]  # Shape becomes (4096, 1)\n",
        "        attention_output = (np.linalg.pinv(W_int) @ (pre_gelu - b_int)).T  # Back to (5, 1024)\n",
        "\n",
        "        # 6. Reverse the first layer norm\n",
        "        prenorm1 = reverse_layer_norm(\n",
        "            attention_output,\n",
        "            layer_params['layernorm1']['gamma'],\n",
        "            layer_params['layernorm1']['beta']\n",
        "        )\n",
        "\n",
        "        # 7. Generate possible attention solutions\n",
        "        attention_gen = find_attention_inputs(\n",
        "            prenorm1,\n",
        "            layer_params['attention_qkv'],\n",
        "            layer_params['attention_output']\n",
        "        )\n",
        "\n",
        "        # Combine all solutions\n",
        "        attention_solution = attention_gen(z_attention)\n",
        "\n",
        "        return attention_solution\n",
        "\n",
        "    return solution_generator"
      ],
      "metadata": {
        "id": "14E-uWkxImMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def extract_layer_params(bert_layer):\n",
        "    \"\"\"Extract parameters from a BertLayer module\"\"\"\n",
        "    params = {}\n",
        "\n",
        "    # Get attention parameters\n",
        "    attention = bert_layer.attention.self\n",
        "    params['attention_qkv'] = {\n",
        "        'query': attention.query.weight.detach().cpu().numpy(),\n",
        "        'query_bias': attention.query.bias.detach().cpu().numpy(),\n",
        "        'key': attention.key.weight.detach().cpu().numpy(),\n",
        "        'key_bias': attention.key.bias.detach().cpu().numpy(),\n",
        "        'value': attention.value.weight.detach().cpu().numpy(),\n",
        "        'value_bias': attention.value.bias.detach().cpu().numpy(),\n",
        "    }\n",
        "\n",
        "    # Attention output projection\n",
        "    params['attention_output'] = {\n",
        "        'weight': bert_layer.attention.output.dense.weight.detach().cpu().numpy(),\n",
        "        'bias': bert_layer.attention.output.dense.bias.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "    # First LayerNorm\n",
        "    params['layernorm1'] = {\n",
        "        'gamma': bert_layer.attention.output.LayerNorm.weight.detach().cpu().numpy(),\n",
        "        'beta': bert_layer.attention.output.LayerNorm.bias.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "    # Intermediate layer\n",
        "    params['intermediate'] = {\n",
        "        'weight': bert_layer.intermediate.dense.weight.detach().cpu().numpy(),\n",
        "        'bias': bert_layer.intermediate.dense.bias.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "    # Output layer\n",
        "    params['output'] = {\n",
        "        'weight': bert_layer.output.dense.weight.detach().cpu().numpy(),\n",
        "        'bias': bert_layer.output.dense.bias.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "    # Second LayerNorm\n",
        "    params['layernorm2'] = {\n",
        "        'gamma': bert_layer.output.LayerNorm.weight.detach().cpu().numpy(),\n",
        "        'beta': bert_layer.output.LayerNorm.bias.detach().cpu().numpy()\n",
        "    }\n",
        "\n",
        "    return params\n",
        "\n",
        "def improve_attention_handling(qkv_weights, attention_output, seq_length=512, num_heads=16):\n",
        "    \"\"\"More detailed attention mechanism inversion\"\"\"\n",
        "    head_size = qkv_weights['query'].shape[0] // num_heads\n",
        "\n",
        "    def attention_solution_generator(z_q, z_k, z_v, temperature=1.0):\n",
        "        # Split z vectors for each head\n",
        "        z_q = z_q.reshape(num_heads, seq_length, head_size)\n",
        "        z_k = z_k.reshape(num_heads, seq_length, head_size)\n",
        "        z_v = z_v.reshape(num_heads, seq_length, head_size)\n",
        "\n",
        "        # Generate possible Q, K, V matrices\n",
        "        Q = np.linalg.pinv(qkv_weights['query']) @ z_q.reshape(-1, head_size * num_heads)\n",
        "        K = np.linalg.pinv(qkv_weights['key']) @ z_k.reshape(-1, head_size * num_heads)\n",
        "        V = np.linalg.pinv(qkv_weights['value']) @ z_v.reshape(-1, head_size * num_heads)\n",
        "\n",
        "        # Reshape to match original dimensions\n",
        "        Q = Q.reshape(seq_length, num_heads, head_size)\n",
        "        K = K.reshape(seq_length, num_heads, head_size)\n",
        "        V = V.reshape(seq_length, num_heads, head_size)\n",
        "\n",
        "        # Scale factor for attention\n",
        "        scale = np.sqrt(head_size)\n",
        "\n",
        "        # Compute attention scores (approximation)\n",
        "        attention_scores = np.matmul(Q, K.transpose(-2, -1)) / scale\n",
        "        attention_probs = np.exp(attention_scores * temperature) / np.sum(np.exp(attention_scores * temperature), axis=-1, keepdims=True)\n",
        "\n",
        "        # Compute attention output\n",
        "        attention_output = np.matmul(attention_probs, V)\n",
        "\n",
        "        return attention_output.reshape(seq_length, -1)\n",
        "\n",
        "    return attention_solution_generator\n",
        "\n",
        "# Example usage:\n",
        "def invert_bert_layer(model, layer_idx, output_tensor):\n",
        "    \"\"\"Invert a specific BERT layer\"\"\"\n",
        "    # Extract parameters\n",
        "    layer = model.encoder.layer[layer_idx]\n",
        "    params = extract_layer_params(layer)\n",
        "\n",
        "    # Create solution generator\n",
        "    solution_gen = find_possible_encoder_inputs(\n",
        "        output_tensor.detach().cpu().numpy(),\n",
        "        params\n",
        "    )\n",
        "\n",
        "    # Generate random z vectors for attention components\n",
        "    seq_length = output_tensor.shape[0]\n",
        "    hidden_size = output_tensor.shape[1]\n",
        "    num_heads = 16  # Assuming 16 attention heads\n",
        "\n",
        "    z_attention = np.random.randn(seq_length, hidden_size)\n",
        "    z_intermediate = np.random.randn(seq_length, hidden_size * 4)  # 4x for intermediate size\n",
        "\n",
        "    # Get possible input\n",
        "    possible_input = solution_gen(z_attention, z_intermediate)\n",
        "\n",
        "    # Add inside invert_bert_layer\n",
        "    attention_output = layer.attention(torch.tensor(possible_input, dtype=torch.float32).unsqueeze(0))[0]\n",
        "    print(f\"Attention similarity: {torch.nn.functional.cosine_similarity(attention_output.flatten(), layer_output[0].flatten(), dim=0).item()}\")\n",
        "\n",
        "    # Get intermediate size correctly\n",
        "    intermediate_output = layer.intermediate(attention_output)\n",
        "    intermediate_layer_output = layer.intermediate(layer_output[0].unsqueeze(0))\n",
        "    print(f\"Intermediate similarity: {torch.nn.functional.cosine_similarity(intermediate_output.flatten(), intermediate_layer_output.flatten(), dim=0).item()}\")\n",
        "\n",
        "    return torch.tensor(possible_input, dtype=output_tensor.dtype, device=output_tensor.device)\n",
        "\n",
        "layer_output = outputs.hidden_states[24]\n",
        "possible_input = invert_bert_layer(model, 23, layer_output[0])\n",
        "\n",
        "layer = model.encoder.layer[23]\n",
        "reconstructed_output = layer(possible_input.unsqueeze(0))[0]\n",
        "\n",
        "# Check similarity\n",
        "similarity = torch.nn.functional.cosine_similarity(\n",
        "    layer_output[0].flatten(),\n",
        "    reconstructed_output.flatten(),\n",
        "    dim=0\n",
        ")\n",
        "print(f\"Reconstruction similarity: {similarity.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFwiv44DI86K",
        "outputId": "904a146c-a9a9-465a-b09f-8b15d8d84428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention similarity: 0.10488615930080414\n",
            "Intermediate similarity: 0.03049367666244507\n",
            "Reconstruction similarity: 0.04939057677984238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.hidden_states[24][0]"
      ],
      "metadata": {
        "id": "k_ujy9pjOE67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3bdf1d-9bc4-4173-da21-9d51a205e8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
              "        [ 0.3397, -0.2081,  0.5046,  ..., -0.1825,  0.4268,  0.7270],\n",
              "        [ 0.6616,  0.0069,  0.7108,  ..., -0.3792,  0.4171,  0.5104],\n",
              "        [ 0.7522,  0.0126,  0.8135,  ..., -0.2740,  0.7368,  0.6462],\n",
              "        [ 0.6640,  0.0345,  0.8832,  ..., -0.0384,  0.6693,  0.5532]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAyjHvtRMq8x",
        "outputId": "fe0bf490-8fcf-44a3-c904-174b8df96092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 1024)\n",
            "    (token_type_embeddings): Embedding(2, 1024)\n",
            "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-23): 24 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.encoder.layer[23].output.dense.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1GNKW2W63xC",
        "outputId": "ceaf547b-e6fb-4158-ddbb-dc5bcd758584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_possible_inputs(normalized_values, weight, bias, input_scale, input_shift):\n",
        "    # First undo LayerNorm's learned transformations\n",
        "    unlearned = [(x - bias[idx]) / weight[idx] for idx,x in enumerate(normalized_values)]\n",
        "    # Now apply our input parameters to generate a possible input sequence\n",
        "    # Any sequence generated this way would normalize to our target output\n",
        "    return [x * input_scale + input_shift for x in unlearned]"
      ],
      "metadata": {
        "id": "DYQTYB9c-0WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "layerNormInput = []\n",
        "layerNormOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global layerNormInput, layerNormOutput\n",
        "    # Access input and output tensors of the LayerNorm module\n",
        "    print(\"LayerNorm Input:\", input[0]) # Accessing the input tensor\n",
        "    layerNormInput = input[0]\n",
        "    print(\"LayerNorm Output:\", output) # Accessing the output tensor\n",
        "    layerNormOutput = output\n",
        "    # Perform desired operations on input and output\n",
        "\n",
        "# Register the hook\n",
        "for hook in model.encoder.layer[23].output.LayerNorm._forward_hooks.copy():\n",
        "    model.encoder.layer[23].output.LayerNorm._forward_hooks.pop(hook)\n",
        "hook = model.encoder.layer[23].output.LayerNorm.register_forward_hook(hook_function)"
      ],
      "metadata": {
        "id": "KX4LARye-62F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pFantYL_Yq8",
        "outputId": "52f20f98-02d3-4cdd-f908-f61305a2666b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LayerNorm Input: tensor([[[ 0.5554,  0.4269,  0.9111,  ..., -0.3931,  0.7964,  1.2763],\n",
            "         [ 0.5362, -0.4190,  0.8229,  ..., -0.2630,  0.9067,  1.4299],\n",
            "         [ 1.0879, -0.0599,  1.1569,  ..., -0.6003,  0.8776,  1.0313],\n",
            "         [ 1.2613, -0.0517,  1.3459,  ..., -0.4244,  1.4467,  1.2856],\n",
            "         [ 0.9892, -0.0169,  1.3106,  ..., -0.0136,  1.1891,  1.0023]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "LayerNorm Output: tensor([[[ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "         [ 0.3397, -0.2081,  0.5046,  ..., -0.1825,  0.4268,  0.7270],\n",
            "         [ 0.6616,  0.0069,  0.7108,  ..., -0.3792,  0.4171,  0.5104],\n",
            "         [ 0.7522,  0.0126,  0.8135,  ..., -0.2740,  0.7368,  0.6462],\n",
            "         [ 0.6640,  0.0345,  0.8832,  ..., -0.0384,  0.6693,  0.5532]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hook.remove()"
      ],
      "metadata": {
        "id": "8eOkY1rmw7CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(layerNormInput[0])\n",
        "print(layerNormOutput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Q-JalDAzCx",
        "outputId": "418bd73b-8636-4509-af10-9d0dd277069b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5554,  0.4269,  0.9111,  ..., -0.3931,  0.7964,  1.2763],\n",
            "        [ 0.5362, -0.4190,  0.8229,  ..., -0.2630,  0.9067,  1.4299],\n",
            "        [ 1.0879, -0.0599,  1.1569,  ..., -0.6003,  0.8776,  1.0313],\n",
            "        [ 1.2613, -0.0517,  1.3459,  ..., -0.4244,  1.4467,  1.2856],\n",
            "        [ 0.9892, -0.0169,  1.3106,  ..., -0.0136,  1.1891,  1.0023]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "        [ 0.3397, -0.2081,  0.5046,  ..., -0.1825,  0.4268,  0.7270],\n",
            "        [ 0.6616,  0.0069,  0.7108,  ..., -0.3792,  0.4171,  0.5104],\n",
            "        [ 0.7522,  0.0126,  0.8135,  ..., -0.2740,  0.7368,  0.6462],\n",
            "        [ 0.6640,  0.0345,  0.8832,  ..., -0.0384,  0.6693,  0.5532]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generatedInput = []\n",
        "for i in layerNormOutput[0]:\n",
        "    result = generate_possible_inputs(i.cpu().clone().detach().numpy(),\n",
        "                            model.encoder.layer[23].output.LayerNorm.weight.cpu().clone().detach().numpy(),\n",
        "                            model.encoder.layer[23].output.LayerNorm.bias.cpu().clone().detach().numpy(), 1, 1)\n",
        "    generatedInput.append(result)\n",
        "\n",
        "generatedInput = torch.tensor([generatedInput], dtype=torch.float32)\n",
        "generatedInput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgmCGlHrBS3m",
        "outputId": "63469dba-2681-44e8-c19b-00e7c60f21e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.4364, 1.3310, 1.7279,  ..., 0.6589, 1.6339, 2.0273],\n",
              "         [1.4112, 0.6452, 1.6410,  ..., 0.7704, 1.7082, 2.1277],\n",
              "         [1.8654, 0.9331, 1.9214,  ..., 0.4941, 1.6946, 1.8195],\n",
              "         [1.9933, 0.9407, 2.0611,  ..., 0.6419, 2.1419, 2.0128],\n",
              "         [1.8688, 0.9700, 2.1559,  ..., 0.9729, 2.0474, 1.8805]]])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputOfGeneratedInput = model.encoder.layer[23].output.LayerNorm(generatedInput)"
      ],
      "metadata": {
        "id": "41XjCfByE80C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(layerNormOutput)\n",
        "print(outputOfGeneratedInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmzWEpLHFijk",
        "outputId": "5806e4e7-321d-401e-b6f7-495e29d83c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "         [ 0.3397, -0.2081,  0.5046,  ..., -0.1825,  0.4268,  0.7270],\n",
            "         [ 0.6616,  0.0069,  0.7108,  ..., -0.3792,  0.4171,  0.5104],\n",
            "         [ 0.7522,  0.0126,  0.8135,  ..., -0.2740,  0.7368,  0.6462],\n",
            "         [ 0.6640,  0.0345,  0.8832,  ..., -0.0384,  0.6693,  0.5532]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([[[ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "         [ 0.3397, -0.2081,  0.5046,  ..., -0.1825,  0.4268,  0.7270],\n",
            "         [ 0.6616,  0.0069,  0.7108,  ..., -0.3792,  0.4171,  0.5104],\n",
            "         [ 0.7522,  0.0126,  0.8135,  ..., -0.2740,  0.7368,  0.6462],\n",
            "         [ 0.6640,  0.0345,  0.8832,  ..., -0.0384,  0.6693,  0.5532]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cmToHEBjTub",
        "outputId": "9b22e201-e63c-47cb-a31c-78297906ae0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 1024)\n",
            "    (token_type_embeddings): Embedding(2, 1024)\n",
            "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-23): 24 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "outputDenseInput = []\n",
        "outputDenseOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global outputDenseInput, outputDenseOutput\n",
        "    print(\"Dense Input:\", input[0]) # Accessing the input tensor\n",
        "    outputDenseInput = input[0]\n",
        "    print(\"Dense Output:\", output) # Accessing the output tensor\n",
        "    outputDenseOutput = output\n",
        "\n",
        "# Register the hook\n",
        "for hook in model.encoder.layer[23].output.dense._forward_hooks.copy():\n",
        "    model.encoder.layer[23].output.dense._forward_hooks.pop(hook)\n",
        "hook = model.encoder.layer[23].output.dense.register_forward_hook(hook_function)"
      ],
      "metadata": {
        "id": "9aV2iIeSja5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch95Fw5Aju4x",
        "outputId": "564ad353-9272-41ba-ea42-22ca31276818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Input: tensor([[[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "          -1.7445e-02, -1.4291e-04],\n",
            "         [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "          -2.0496e-02, -7.1462e-05],\n",
            "         [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "          -2.7109e-02, -1.1580e-04],\n",
            "         [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "          -4.2538e-02, -5.4290e-05],\n",
            "         [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "          -4.1407e-02, -1.9358e-04]]], grad_fn=<GeluBackward0>)\n",
            "Dense Output: tensor([[[-0.0252, -0.1483, -0.0521,  ..., -0.0213, -0.0147,  0.0333],\n",
            "         [-0.1382, -0.1020, -0.1916,  ...,  0.0017, -0.0260, -0.1250],\n",
            "         [-0.0498, -0.1138, -0.0421,  ..., -0.0419, -0.0629,  0.0403],\n",
            "         [-0.0752, -0.1497, -0.1350,  ..., -0.0377, -0.0197,  0.0146],\n",
            "         [-0.1024, -0.1323, -0.1386,  ..., -0.1830,  0.0392, -0.0618]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputDenseInput[0])\n",
        "print(outputDenseOutput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiX_WyU6j5iP",
        "outputId": "e9de832f-642d-49ac-c78f-c0ae4f6229f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "         -1.7445e-02, -1.4291e-04],\n",
            "        [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "         -2.0496e-02, -7.1462e-05],\n",
            "        [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "         -2.7109e-02, -1.1580e-04],\n",
            "        [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "         -4.2538e-02, -5.4290e-05],\n",
            "        [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "         -4.1407e-02, -1.9358e-04]], grad_fn=<SelectBackward0>)\n",
            "tensor([[-0.0252, -0.1483, -0.0521,  ..., -0.0213, -0.0147,  0.0333],\n",
            "        [-0.1382, -0.1020, -0.1916,  ...,  0.0017, -0.0260, -0.1250],\n",
            "        [-0.0498, -0.1138, -0.0421,  ..., -0.0419, -0.0629,  0.0403],\n",
            "        [-0.0752, -0.1497, -0.1350,  ..., -0.0377, -0.0197,  0.0146],\n",
            "        [-0.1024, -0.1323, -0.1386,  ..., -0.1830,  0.0392, -0.0618]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputDenseOutputNoBias = []\n",
        "for idx,i in enumerate(outputDenseOutput[0]):\n",
        "    row = []\n",
        "    for jdx,j in enumerate(i):\n",
        "        row.append(j.item() - model.encoder.layer[23].output.dense.bias[jdx].item())\n",
        "    outputDenseOutputNoBias.append(row)\n",
        "outputDenseOutputNoBias = np.array(outputDenseOutputNoBias)\n",
        "print(outputDenseOutputNoBias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DtR5o-ckN1Q",
        "outputId": "8e04dff6-174f-4b39-fef4-f31656c6058e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.03669279 -0.1382297  -0.02500452 ... -0.01930995  0.01228103\n",
            "   0.02942588]\n",
            " [-0.14971916 -0.09190643 -0.16448414 ...  0.00372266  0.00096926\n",
            "  -0.12894103]\n",
            " [-0.06131524 -0.10368666 -0.01503783 ... -0.03990428 -0.03591686\n",
            "   0.03643085]\n",
            " [-0.08663716 -0.13963175 -0.10794523 ... -0.03569643  0.00730003\n",
            "   0.01073178]\n",
            " [-0.11385674 -0.12217624 -0.11153029 ... -0.18102244  0.06613217\n",
            "  -0.06566171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def allInputsForMatrixProduct(y, W):\n",
        "    W_pinv = np.linalg.pinv(W)\n",
        "\n",
        "    # Create nullspace projection matrix\n",
        "    I = np.eye(W.shape[1])\n",
        "    nullspace_proj = I - W_pinv @ W\n",
        "\n",
        "    # Return function that generates solutions for any z\n",
        "    def solution_generator(z):\n",
        "        particular_solution = W_pinv @ y\n",
        "        nullspace_component = nullspace_proj @ z\n",
        "        print(\"Nullspace component magnitude:\", np.linalg.norm(nullspace_proj @ z))\n",
        "        print(\"Particular solution magnitude:\", np.linalg.norm(particular_solution))\n",
        "        return particular_solution + nullspace_component\n",
        "\n",
        "    return solution_generator\n",
        "\n",
        "# # Create sample data\n",
        "# n = 1024  # Using small dimension for example\n",
        "# W = model.pooler.dense.weight.cpu().detach().clone().numpy()\n",
        "# b = model.pooler.dense.bias.cpu().detach().clone().numpy()\n",
        "# x_original = outputs.hidden_states[24][0][0].cpu().clone().detach().numpy()\n",
        "# y = outputs.pooler_output[0].cpu().clone().detach().numpy()\n",
        "\n",
        "# # Find solution generator\n",
        "# solution_gen = find_all_possible_inputs(y, W, b)\n",
        "\n",
        "# # Generate some solutions\n",
        "# z = np.random.randn(n)\n",
        "# x_solution = solution_gen(z)\n",
        "\n",
        "# # Verify solution\n",
        "# y_reconstructed = np.tanh(W @ x_solution + b)\n",
        "# print(\"Original y:\", y)\n",
        "# print(\"Reconstructed y:\", y_reconstructed)\n",
        "# print(\"Original x:\", x_original)\n",
        "# print(\"Reconstructed x:\", x_solution)\n",
        "# print(\"Difference in input:\", cosine_similarity(torch.tensor(outputs.hidden_states[24][0][0].clone().detach(), dtype=torch.float32),\n",
        "#                                                 torch.tensor(x_solution, dtype=torch.float32)))\n",
        "# print(\"Difference in output:\", cosine_similarity(torch.tensor(y, dtype=torch.float32), torch.tensor(y_reconstructed, dtype=torch.float32)))"
      ],
      "metadata": {
        "id": "_Gf7uF89mzI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "solutionGens = []\n",
        "for idx,i in tqdm(enumerate(outputDenseOutputNoBias)):\n",
        "    solutionGens.append(allInputsForMatrixProduct(i, model.encoder.layer[23].output.dense.weight.cpu().detach().clone().numpy()))\n",
        "\n",
        "solutionGens = np.array(solutionGens)\n",
        "print(solutionGens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "324rExJNlOwh",
        "outputId": "c3bc64c3-e429-49fe-ec93-1731f4bc16f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:18,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1af9aff60>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1af900540>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1af9004a0>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1af9005e0>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1af900680>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoderBias = model.encoder.layer[23].output.dense.bias.cpu().detach().clone().numpy()\n",
        "encoderBias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdU_1jUvZ8nW",
        "outputId": "a24462f1-65eb-4784-c192-64fd0bf4fd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dims = np.zeros(4096)\n",
        "resultingDenseInput = [i(dims) for i in solutionGens]\n",
        "print(resultingDenseInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQdirKTloiWB",
        "outputId": "6b5d851b-f3fe-457c-ebaf-ea81cbfb010b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 1.376521034460357\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 1.8995527000425831\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 1.7386351733987548\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 1.9867662226272622\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 2.301452252502951\n",
            "[array([ 0.01325531, -0.04846144, -0.02368549, ...,  0.00823128,\n",
            "       -0.03177362,  0.01280792]), array([-0.00793737, -0.05799633, -0.03510541, ..., -0.0157737 ,\n",
            "       -0.03550087,  0.03971293]), array([-0.00032944, -0.06061508, -0.04295083, ...,  0.00911805,\n",
            "       -0.04231749,  0.03297237]), array([-0.00839184, -0.07283129, -0.03830097, ..., -0.00020523,\n",
            "       -0.05334458,  0.01368061]), array([-0.00591022, -0.07854552, -0.05461421, ..., -0.02209942,\n",
            "       -0.02649114,  0.0218038 ])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch.tensor(resultingDenseInput): \")\n",
        "print(torch.tensor(resultingDenseInput))\n",
        "print(\"outputDenseInput[0]\")\n",
        "print(outputDenseInput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8diV3WlzXC",
        "outputId": "af2c8fc6-705d-4834-9862-00d10a652f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.tensor(resultingDenseInput): \n",
            "tensor([[ 0.0133, -0.0485, -0.0237,  ...,  0.0082, -0.0318,  0.0128],\n",
            "        [-0.0079, -0.0580, -0.0351,  ..., -0.0158, -0.0355,  0.0397],\n",
            "        [-0.0003, -0.0606, -0.0430,  ...,  0.0091, -0.0423,  0.0330],\n",
            "        [-0.0084, -0.0728, -0.0383,  ..., -0.0002, -0.0533,  0.0137],\n",
            "        [-0.0059, -0.0785, -0.0546,  ..., -0.0221, -0.0265,  0.0218]],\n",
            "       dtype=torch.float64)\n",
            "outputDenseInput[0]\n",
            "tensor([[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "         -1.7445e-02, -1.4291e-04],\n",
            "        [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "         -2.0496e-02, -7.1462e-05],\n",
            "        [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "         -2.7109e-02, -1.1580e-04],\n",
            "        [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "         -4.2538e-02, -5.4290e-05],\n",
            "        [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "         -4.1407e-02, -1.9358e-04]], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-9e116bd199fc>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  print(torch.tensor(resultingDenseInput))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert weights and bias to numpy for consistency\n",
        "weights = model.encoder.layer[23].output.dense.weight.cpu().detach().numpy()\n",
        "bias = model.encoder.layer[23].output.dense.bias.cpu().detach().numpy()\n",
        "\n",
        "# Check each token\n",
        "for i in range(5):  # 5 tokens\n",
        "    # Our reconstructed solution\n",
        "    our_output = weights @ resultingDenseInput[i] + bias\n",
        "    # Original output\n",
        "    original_output = outputDenseOutput[0][i].cpu().detach().numpy()\n",
        "\n",
        "    # Check if they're equal within some tolerance\n",
        "    is_close = np.allclose(our_output, original_output, rtol=1e-5, atol=1e-5)\n",
        "    diff_magnitude = np.linalg.norm(our_output - original_output)\n",
        "\n",
        "    print(f\"\\nToken {i}:\")\n",
        "    print(f\"Outputs match within tolerance? {is_close}\")\n",
        "    print(f\"Difference magnitude: {diff_magnitude}\")\n",
        "\n",
        "    # Check if both inputs produce valid outputs\n",
        "    original_input = outputDenseInput[0][i].cpu().detach().numpy()\n",
        "    original_output_check = weights @ original_input + bias\n",
        "    our_output_check = weights @ resultingDenseInput[i] + bias\n",
        "\n",
        "    print(\"\\nBoth solutions valid?\")\n",
        "    print(f\"Original input produces correct output? {np.allclose(original_output_check, original_output, rtol=1e-5, atol=1e-5)}\")\n",
        "    print(f\"Our input produces correct output? {np.allclose(our_output_check, original_output, rtol=1e-5, atol=1e-5)}\")\n",
        "\n",
        "    # Check if inputs lie in different parts of nullspace\n",
        "    diff_vector = resultingDenseInput[i] - original_input\n",
        "    nullspace_component = diff_vector - (weights.T @ np.linalg.pinv(weights.T) @ diff_vector)\n",
        "    nullspace_magnitude = np.linalg.norm(nullspace_component)\n",
        "\n",
        "    print(f\"\\nDifference between solutions:\")\n",
        "    print(f\"Total magnitude: {np.linalg.norm(diff_vector)}\")\n",
        "    print(f\"Nullspace component magnitude: {nullspace_magnitude}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsjqIxC9q8gN",
        "outputId": "088bc850-1cb9-439d-e391-3ac1b30af694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token 0:\n",
            "Outputs match within tolerance? True\n",
            "Difference magnitude: 9.364408901727101e-07\n",
            "\n",
            "Both solutions valid?\n",
            "Original input produces correct output? True\n",
            "Our input produces correct output? True\n",
            "\n",
            "Difference between solutions:\n",
            "Total magnitude: 2.4665615101187885\n",
            "Nullspace component magnitude: 2.4665614477240765\n",
            "\n",
            "Token 1:\n",
            "Outputs match within tolerance? True\n",
            "Difference magnitude: 1.4894001734759556e-06\n",
            "\n",
            "Both solutions valid?\n",
            "Original input produces correct output? True\n",
            "Our input produces correct output? True\n",
            "\n",
            "Difference between solutions:\n",
            "Total magnitude: 3.081327917859019\n",
            "Nullspace component magnitude: 3.081327917076822\n",
            "\n",
            "Token 2:\n",
            "Outputs match within tolerance? True\n",
            "Difference magnitude: 1.3262315198560109e-06\n",
            "\n",
            "Both solutions valid?\n",
            "Original input produces correct output? True\n",
            "Our input produces correct output? True\n",
            "\n",
            "Difference between solutions:\n",
            "Total magnitude: 2.95776654852769\n",
            "Nullspace component magnitude: 2.9577665095350287\n",
            "\n",
            "Token 3:\n",
            "Outputs match within tolerance? True\n",
            "Difference magnitude: 1.7849663329125144e-06\n",
            "\n",
            "Both solutions valid?\n",
            "Original input produces correct output? True\n",
            "Our input produces correct output? True\n",
            "\n",
            "Difference between solutions:\n",
            "Total magnitude: 3.110318848200933\n",
            "Nullspace component magnitude: 3.1103188195702125\n",
            "\n",
            "Token 4:\n",
            "Outputs match within tolerance? True\n",
            "Difference magnitude: 2.1439134221301836e-06\n",
            "\n",
            "Both solutions valid?\n",
            "Original input produces correct output? True\n",
            "Our input produces correct output? True\n",
            "\n",
            "Difference between solutions:\n",
            "Total magnitude: 3.819523860868452\n",
            "Nullspace component magnitude: 3.819523790512137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_z_for_exact_match(original_input, target_output, weights):\n",
        "    # Get pseudoinverse\n",
        "    W_pinv = np.linalg.pinv(weights)\n",
        "\n",
        "    # Calculate nullspace projection matrix\n",
        "    I = np.eye(weights.shape[1])\n",
        "    nullspace_proj = I - W_pinv @ weights\n",
        "\n",
        "    # Solve for z: (I - W⁺W)z = x - W⁺y\n",
        "    # Using pseudoinverse again because (I - W⁺W) might be singular\n",
        "    left_side = original_input - (W_pinv @ target_output)\n",
        "    z = np.linalg.pinv(nullspace_proj) @ left_side\n",
        "\n",
        "    # Verify the solution\n",
        "    reconstructed = W_pinv @ target_output + nullspace_proj @ z\n",
        "    print(\"Reconstruction error:\", np.linalg.norm(reconstructed - original_input))\n",
        "\n",
        "    return z\n",
        "\n",
        "# Test for each token\n",
        "for i in range(5):\n",
        "    target_output = outputDenseOutputNoBias[i]\n",
        "    original_input = outputDenseInput[0][i].cpu().detach().numpy()\n",
        "    weights = model.encoder.layer[23].output.dense.weight.cpu().detach().numpy()\n",
        "\n",
        "    print(f\"\\nToken {i}:\")\n",
        "    z = find_z_for_exact_match(original_input, target_output, weights)\n",
        "    print(f'For z={z}')\n",
        "\n",
        "    dims = dims = np.full(4096, z)\n",
        "    exactSolution = solutionGens[i](dims)\n",
        "    print(exactSolution)\n",
        "    print(outputDenseInput[0][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prlIVO2NrmHC",
        "outputId": "2116607a-b494-4bc7-9127-6d79e6cf505f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token 0:\n",
            "Reconstruction error: 3.390478630281596e-07\n",
            "For z=[ 0.3934189  -4.53125236  1.58302055 ... -1.17958133 -2.5554234\n",
            "  3.30555189]\n",
            "Nullspace component magnitude: 2.4665615071679388\n",
            "Particular solution magnitude: 1.376521034460357\n",
            "[-1.73217581e-05 -5.15382737e-02 -6.59669667e-05 ... -9.88914530e-05\n",
            " -1.74452481e-02 -1.42911737e-04]\n",
            "tensor([-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "        -1.7445e-02, -1.4291e-04], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Token 1:\n",
            "Reconstruction error: 3.5806466698569166e-07\n",
            "For z=[-0.79488326 -8.01141875  1.43890188 ... -2.24753455 -3.07402408\n",
            " 13.86736469]\n",
            "Nullspace component magnitude: 3.0813279189927525\n",
            "Particular solution magnitude: 1.8995527000425831\n",
            "[-1.82143386e-04 -5.97077181e-02 -3.33357477e-04 ... -1.12247751e-03\n",
            " -2.04959208e-02 -7.14417621e-05]\n",
            "tensor([-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "        -2.0496e-02, -7.1462e-05], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Token 2:\n",
            "Reconstruction error: 4.5782337494968854e-07\n",
            "For z=[ -8.84770193  16.75012734  -8.11448547 ...   9.34307181  19.87832402\n",
            " -36.37117368]\n",
            "Nullspace component magnitude: 2.957766544447153\n",
            "Particular solution magnitude: 1.7386351733987548\n",
            "[-5.34683557e-05 -6.57048502e-02 -2.54033314e-04 ... -7.28560588e-05\n",
            " -2.71093840e-02 -1.15803815e-04]\n",
            "tensor([-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "        -2.7109e-02, -1.1580e-04], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Token 3:\n",
            "Reconstruction error: 4.140735525307501e-07\n",
            "For z=[ -5.73928343   5.08395465  -2.29068154 ...   4.67323329  14.58017999\n",
            " -22.25191325]\n",
            "Nullspace component magnitude: 3.1103188539157456\n",
            "Particular solution magnitude: 1.9867662226272622\n",
            "[-1.85522923e-04 -8.79573226e-02 -9.19790994e-04 ... -7.36721191e-05\n",
            " -4.25378875e-02 -5.42951170e-05]\n",
            "tensor([-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "        -4.2538e-02, -5.4290e-05], grad_fn=<SelectBackward0>)\n",
            "\n",
            "Token 4:\n",
            "Reconstruction error: 4.457604716704157e-07\n",
            "For z=[  2.93468808  -8.72246705   6.32854384 ... -10.13055394 -16.35475732\n",
            "  31.84036811]\n",
            "Nullspace component magnitude: 3.8195238461262835\n",
            "Particular solution magnitude: 2.301452252502951\n",
            "[-1.18111962e-05 -1.11583208e-01 -1.82790918e-04 ... -1.16990551e-03\n",
            " -4.14066884e-02 -1.93555454e-04]\n",
            "tensor([-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "        -4.1407e-02, -1.9358e-04], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import erf\n",
        "\n",
        "def gelu_vectorized(x):\n",
        "    \"\"\"Vectorized GELU activation\"\"\"\n",
        "    return 0.5 * x * (1 + erf(x / np.sqrt(2)))\n",
        "\n",
        "def gelu_derivative_vectorized(x):\n",
        "    \"\"\"Vectorized GELU derivative\"\"\"\n",
        "    return 0.5 * (1 + erf(x / np.sqrt(2))) + \\\n",
        "           (x * np.exp(-(x**2) / 2)) / (2 * np.sqrt(2 * np.pi))\n",
        "\n",
        "def inverse_gelu_matrix(target_matrix, max_iter=50, tol=1e-7):\n",
        "    \"\"\"\n",
        "    Vectorized Newton's method for GELU inverse on matrices\n",
        "\n",
        "    Args:\n",
        "        target_matrix: Matrix of target values\n",
        "        max_iter: Maximum iterations\n",
        "        tol: Convergence tolerance\n",
        "    \"\"\"\n",
        "    # Initial guess\n",
        "    x = target_matrix * 1.7  # Vectorized initial guess\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        # Compute function value and derivative\n",
        "        fx = gelu_vectorized(x) - target_matrix\n",
        "        fpx = gelu_derivative_vectorized(x)\n",
        "\n",
        "        # Newton step\n",
        "        step = fx / fpx\n",
        "        x_new = x - step\n",
        "\n",
        "        # Check convergence\n",
        "        if np.max(np.abs(step)) < tol:\n",
        "            return x_new\n",
        "\n",
        "        x = x_new\n",
        "\n",
        "    return x  # Return best estimate if max_iter reached"
      ],
      "metadata": {
        "id": "0ZuOBoHDgWV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "intermediateGELUInput = []\n",
        "intermediateGELUOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global intermediateGELUInput, intermediateGELUOutput\n",
        "    print(\"Input:\", input[0]) # Accessing the input tensor\n",
        "    intermediateGELUInput = input[0]\n",
        "    print(\"Output:\", output) # Accessing the output tensor\n",
        "    intermediateGELUOutput = output\n",
        "\n",
        "hook = model.encoder.layer[23].intermediate.intermediate_act_fn.register_forward_hook(hook_function)\n",
        "\n",
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "print(intermediateGELUInput[0])\n",
        "print(intermediateGELUOutput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjZ_slizh9Y5",
        "outputId": "0a689f65-8a0e-483c-d012-71305535ed71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[[-4.4706, -1.9321, -4.1605,  ..., -4.0615, -2.4513, -3.9695],\n",
            "         [-3.9076, -1.8479, -3.7485,  ..., -3.4060, -2.3822, -4.1414],\n",
            "         [-4.2110, -1.7903, -3.8208,  ..., -4.1366, -2.2567, -4.0224],\n",
            "         [-3.9028, -1.5977, -3.4646,  ..., -4.1339, -2.0356, -4.2071],\n",
            "         [-4.5562, -1.4115, -3.9067,  ..., -3.3938, -2.0496, -3.8918]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "Output: tensor([[[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "          -1.7445e-02, -1.4291e-04],\n",
            "         [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "          -2.0496e-02, -7.1462e-05],\n",
            "         [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "          -2.7109e-02, -1.1580e-04],\n",
            "         [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "          -4.2538e-02, -5.4290e-05],\n",
            "         [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "          -4.1407e-02, -1.9358e-04]]], grad_fn=<GeluBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[-4.4706, -1.9321, -4.1605,  ..., -4.0615, -2.4513, -3.9695],\n",
            "        [-3.9076, -1.8479, -3.7485,  ..., -3.4060, -2.3822, -4.1414],\n",
            "        [-4.2110, -1.7903, -3.8208,  ..., -4.1366, -2.2567, -4.0224],\n",
            "        [-3.9028, -1.5977, -3.4646,  ..., -4.1339, -2.0356, -4.2071],\n",
            "        [-4.5562, -1.4115, -3.9067,  ..., -3.3938, -2.0496, -3.8918]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "         -1.7445e-02, -1.4291e-04],\n",
            "        [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "         -2.0496e-02, -7.1462e-05],\n",
            "        [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "         -2.7109e-02, -1.1580e-04],\n",
            "        [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "         -4.2538e-02, -5.4290e-05],\n",
            "        [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "         -4.1407e-02, -1.9358e-04]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reversedGELU = inverse_gelu_matrix(intermediateGELUOutput[0].cpu().clone().detach().numpy())"
      ],
      "metadata": {
        "id": "eojupv1ulrGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gelu_vectorized(reversedGELU))\n",
        "print(intermediateGELUOutput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRDLHmnil-sU",
        "outputId": "07d1f3a0-ef68-44ed-ccee-a0eda7ae00ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.7320603e-05 -5.1538274e-02 -6.5963817e-05 ... -9.8892284e-05\n",
            "  -1.7445240e-02 -1.4290537e-04]\n",
            " [-1.8213603e-04 -5.9707712e-02 -3.3335679e-04 ... -1.1224754e-03\n",
            "  -2.0495931e-02 -7.1461945e-05]\n",
            " [-5.3462307e-05 -6.5704845e-02 -2.5404082e-04 ... -7.2857809e-05\n",
            "  -2.7109370e-02 -1.1580206e-04]\n",
            " [-1.8551963e-04 -8.7957323e-02 -9.1979059e-04 ... -7.3674186e-05\n",
            "  -4.2537890e-02 -5.4290227e-05]\n",
            " [-1.1813439e-05 -1.1158320e-01 -1.8279089e-04 ... -1.1699056e-03\n",
            "  -4.1406702e-02 -1.9357768e-04]]\n",
            "tensor([[-1.7321e-05, -5.1538e-02, -6.5964e-05,  ..., -9.8892e-05,\n",
            "         -1.7445e-02, -1.4291e-04],\n",
            "        [-1.8214e-04, -5.9708e-02, -3.3336e-04,  ..., -1.1225e-03,\n",
            "         -2.0496e-02, -7.1462e-05],\n",
            "        [-5.3462e-05, -6.5705e-02, -2.5404e-04,  ..., -7.2858e-05,\n",
            "         -2.7109e-02, -1.1580e-04],\n",
            "        [-1.8552e-04, -8.7957e-02, -9.1979e-04,  ..., -7.3674e-05,\n",
            "         -4.2538e-02, -5.4290e-05],\n",
            "        [-1.1813e-05, -1.1158e-01, -1.8279e-04,  ..., -1.1699e-03,\n",
            "         -4.1407e-02, -1.9358e-04]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "intermediateDenseInput = []\n",
        "intermediateDenseOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global intermediateDenseInput, intermediateDenseOutput\n",
        "    print(\"Input:\", input[0]) # Accessing the input tensor\n",
        "    intermediateDenseInput = input[0]\n",
        "    print(\"Output:\", output) # Accessing the output tensor\n",
        "    intermediateDenseOutput = output\n",
        "\n",
        "hook = model.encoder.layer[23].intermediate.dense.register_forward_hook(hook_function)\n",
        "\n",
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "print(intermediateDenseInput[0])\n",
        "print(intermediateDenseOutput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd0DapgAmubx",
        "outputId": "f18af51a-0785-4a37-f32a-3cad19237ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "         [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "         [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "         [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "         [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Output: tensor([[[-4.4706, -1.9321, -4.1605,  ..., -4.0615, -2.4513, -3.9695],\n",
            "         [-3.9076, -1.8479, -3.7485,  ..., -3.4060, -2.3822, -4.1414],\n",
            "         [-4.2110, -1.7903, -3.8208,  ..., -4.1366, -2.2567, -4.0224],\n",
            "         [-3.9028, -1.5977, -3.4646,  ..., -4.1339, -2.0356, -4.2071],\n",
            "         [-4.5562, -1.4115, -3.9067,  ..., -3.3938, -2.0496, -3.8918]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "        [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "        [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "        [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "        [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[-4.4706, -1.9321, -4.1605,  ..., -4.0615, -2.4513, -3.9695],\n",
            "        [-3.9076, -1.8479, -3.7485,  ..., -3.4060, -2.3822, -4.1414],\n",
            "        [-4.2110, -1.7903, -3.8208,  ..., -4.1366, -2.2567, -4.0224],\n",
            "        [-3.9028, -1.5977, -3.4646,  ..., -4.1339, -2.0356, -4.2071],\n",
            "        [-4.5562, -1.4115, -3.9067,  ..., -3.3938, -2.0496, -3.8918]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intemediateDenseNoBias = (intermediateDenseOutput[0] - model.encoder.layer[23].intermediate.dense.bias).cpu().detach().clone().numpy()"
      ],
      "metadata": {
        "id": "Fh1rW8mknKqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "solutionGens = []\n",
        "for idx,i in tqdm(enumerate(intemediateDenseNoBias)):\n",
        "    solutionGens.append(allInputsForMatrixProduct(i, model.encoder.layer[23].intermediate.dense.weight.cpu().detach().clone().numpy()))\n",
        "\n",
        "solutionGens = np.array(solutionGens)\n",
        "print(solutionGens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHhhOdwnQ83",
        "outputId": "f855fed8-eeb6-4816-d4be-4207e2024506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:11,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159723c40>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159723920>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159722d40>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159722c00>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159721da0>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dims = np.zeros(1024)\n",
        "resultingIntermediateDenseInput = [i(dims) for i in solutionGens]\n",
        "print(resultingIntermediateDenseInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBwmnbK1nstO",
        "outputId": "bd53b8c3-f631-4f5a-fa27-8085d60da1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 36.946682\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 36.904884\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 36.394157\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 36.059853\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 29.906397\n",
            "[array([ 0.58063626,  0.57521677,  0.96320605, ..., -0.3718136 ,\n",
            "        0.81107795,  1.24302125]), array([ 0.67448246, -0.31703091,  1.01441848, ..., -0.26465213,\n",
            "        0.93275082,  1.5549624 ]), array([ 1.13774526,  0.05387092,  1.19896615, ..., -0.55835158,\n",
            "        0.9404639 ,  0.99097729]), array([ 1.33649552,  0.09805036,  1.48092401, ..., -0.3866941 ,\n",
            "        1.46635091,  1.27099895]), array([1.09161532, 0.11540878, 1.44916177, ..., 0.16942024, 1.14996302,\n",
            "       1.06405413])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch.tensor(resultingIntermediateDenseInput): \")\n",
        "print(torch.tensor(resultingIntermediateDenseInput))\n",
        "print(\"intermediateDenseInput[0]\")\n",
        "print(intermediateDenseInput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-YPI59GoOfJ",
        "outputId": "df16bb85-7d84-4a89-a296-eb5d26be112f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.tensor(resultingIntermediateDenseInput): \n",
            "tensor([[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "        [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "        [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "        [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "        [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]],\n",
            "       dtype=torch.float64)\n",
            "intermediateDenseInput[0]\n",
            "tensor([[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "        [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "        [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "        [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "        [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_possible_inputs(normalized_values, weight, bias, input_scale, input_shift):\n",
        "    # First undo LayerNorm's learned transformations\n",
        "    unlearned = [(x - bias[idx]) / weight[idx] for idx,x in enumerate(normalized_values)]\n",
        "    # Now apply our input parameters to generate a possible input sequence\n",
        "    # Any sequence generated this way would normalize to our target output\n",
        "    return [x * input_scale + input_shift for x in unlearned]"
      ],
      "metadata": {
        "id": "7BT7j9mxzp33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "layerNormInput = []\n",
        "layerNormOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global layerNormInput, layerNormOutput\n",
        "    # Access input and output tensors of the LayerNorm module\n",
        "    # print(\"LayerNorm Input:\", input[0]) # Accessing the input tensor\n",
        "    layerNormInput = input[0]\n",
        "    # print(\"LayerNorm Output:\", output) # Accessing the output tensor\n",
        "    layerNormOutput = output\n",
        "    # Perform desired operations on input and output\n",
        "\n",
        "# Register the hook\n",
        "hook = model.encoder.layer[23].attention.output.LayerNorm.register_forward_hook(hook_function)\n",
        "\n",
        "model.encoder.layer[23](outputs.hidden_states[23])[0][0][0]\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "print(layerNormInput[0])\n",
        "print(layerNormOutput[0])\n",
        "\n",
        "generatedInput = []\n",
        "for i in layerNormOutput[0]:\n",
        "    result = generate_possible_inputs(i,\n",
        "                                      model.encoder.layer[23].attention.output.LayerNorm.weight,\n",
        "                                      model.encoder.layer[23].attention.output.LayerNorm.bias,\n",
        "                                      1,1)\n",
        "    generatedInput.append(result)\n",
        "\n",
        "generatedInput = torch.tensor([generatedInput], dtype=torch.float32)\n",
        "print(generatedInput)\n",
        "\n",
        "outputOfGeneratedInput = model.encoder.layer[23].attention.output.LayerNorm(generatedInput)\n",
        "\n",
        "print(layerNormOutput)\n",
        "print(outputOfGeneratedInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL1bnVHVpKVJ",
        "outputId": "4fd971b7-ed39-4c67-e3ac-f699a8d8615b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5685,  0.5790,  0.9570,  ..., -0.3781,  0.8303,  1.2775],\n",
            "        [ 0.7653, -0.4000,  1.1650,  ..., -0.3042,  1.1001,  1.8476],\n",
            "        [ 1.1353,  0.0377,  1.2059,  ..., -0.5792,  0.9676,  1.0232],\n",
            "        [ 1.5336,  0.0968,  1.7163,  ..., -0.4546,  1.7235,  1.5105],\n",
            "        [ 0.7091,  0.0647,  0.9533,  ...,  0.1254,  0.7689,  0.7162]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "        [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "        [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "        [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "        [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[[1.6635, 1.6758, 2.1161,  ..., 0.5607, 1.9685, 2.4895],\n",
            "         [1.7732, 0.5958, 2.1769,  ..., 0.6926, 2.1114, 2.8666],\n",
            "         [2.3144, 1.0447, 2.3960,  ..., 0.3311, 2.1204, 2.1847],\n",
            "         [2.5466, 1.0982, 2.7308,  ..., 0.5424, 2.7380, 2.5233],\n",
            "         [2.2605, 1.1192, 2.6930,  ..., 1.2268, 2.3665, 2.2731]]])\n",
            "tensor([[[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "         [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "         [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "         [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "         [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "tensor([[[ 0.5806,  0.5752,  0.9632,  ..., -0.3718,  0.8111,  1.2430],\n",
            "         [ 0.6745, -0.3170,  1.0144,  ..., -0.2647,  0.9328,  1.5550],\n",
            "         [ 1.1377,  0.0539,  1.1990,  ..., -0.5584,  0.9405,  0.9910],\n",
            "         [ 1.3365,  0.0981,  1.4809,  ..., -0.3867,  1.4664,  1.2710],\n",
            "         [ 1.0916,  0.1154,  1.4492,  ...,  0.1694,  1.1500,  1.0641]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "intermediateOutputDenseInput = []\n",
        "intermediateOutputDenseOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global intermediateOutputDenseInput, intermediateOutputDenseOutput\n",
        "    print(\"Input:\", input[0]) # Accessing the input tensor\n",
        "    intermediateOutputDenseInput = input[0]\n",
        "    print(\"Output:\", output) # Accessing the output tensor\n",
        "    intermediateOutputDenseOutput = output\n",
        "\n",
        "hook = model.encoder.layer[23].attention.output.dense.register_forward_hook(hook_function)\n",
        "\n",
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "print(intermediateOutputDenseInput[0])\n",
        "print(intermediateOutputDenseOutput[0])\n",
        "\n",
        "intemediateDenseNoBias = (intermediateOutputDenseOutput[0] - model.encoder.layer[23].attention.output.dense.bias).cpu().detach().clone().numpy()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "solutionGens = []\n",
        "for idx,i in tqdm(enumerate(intemediateDenseNoBias)):\n",
        "    solutionGens.append(allInputsForMatrixProduct(i, model.encoder.layer[23].attention.output.dense.weight.cpu().detach().clone().numpy()))\n",
        "\n",
        "solutionGens = np.array(solutionGens)\n",
        "print(solutionGens)\n",
        "\n",
        "dims = np.zeros(1024)\n",
        "resultingAttentionOutputDenseInput = [i(dims) for i in solutionGens]\n",
        "print(resultingAttentionOutputDenseInput)\n",
        "\n",
        "print(\"torch.tensor(resultingAttentionOutputDenseInput): \")\n",
        "print(torch.tensor(resultingAttentionOutputDenseInput))\n",
        "print(\"intermediateOutputDenseInput[0]\")\n",
        "print(intermediateOutputDenseInput[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SW7nrb0qw7Q",
        "outputId": "9b1e34c4-741f-4736-9f0f-dc76e493cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[[-0.2757,  0.2522,  0.2764,  ...,  0.2808,  0.0787, -0.3979],\n",
            "         [-0.2768,  0.3125,  0.2725,  ...,  0.2945,  0.1057, -0.3365],\n",
            "         [-0.2640,  0.2448,  0.2652,  ...,  0.2856,  0.0821, -0.3875],\n",
            "         [-0.2808,  0.2613,  0.2777,  ...,  0.2939,  0.0767, -0.3722],\n",
            "         [-0.2653,  0.2244,  0.2714,  ...,  0.2825,  0.0847, -0.3912]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "Output: tensor([[[ 0.2274,  0.0366,  0.6455,  ..., -0.1713,  0.7352,  0.7677],\n",
            "         [ 0.3078, -0.0030,  0.6157,  ..., -0.2018,  0.7455,  0.8893],\n",
            "         [ 0.2508,  0.0371,  0.6191,  ..., -0.1547,  0.7390,  0.7356],\n",
            "         [ 0.2335, -0.0481,  0.7434,  ..., -0.1977,  0.8662,  0.9425],\n",
            "         [ 0.2419,  0.0430,  0.5891,  ..., -0.1102,  0.7339,  0.6662]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 0.3576,  0.3042,  0.5685,  ..., -0.2619,  0.3737,  0.6564],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[-0.2757,  0.2522,  0.2764,  ...,  0.2808,  0.0787, -0.3979],\n",
            "        [-0.2768,  0.3125,  0.2725,  ...,  0.2945,  0.1057, -0.3365],\n",
            "        [-0.2640,  0.2448,  0.2652,  ...,  0.2856,  0.0821, -0.3875],\n",
            "        [-0.2808,  0.2613,  0.2777,  ...,  0.2939,  0.0767, -0.3722],\n",
            "        [-0.2653,  0.2244,  0.2714,  ...,  0.2825,  0.0847, -0.3912]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([[ 0.2274,  0.0366,  0.6455,  ..., -0.1713,  0.7352,  0.7677],\n",
            "        [ 0.3078, -0.0030,  0.6157,  ..., -0.2018,  0.7455,  0.8893],\n",
            "        [ 0.2508,  0.0371,  0.6191,  ..., -0.1547,  0.7390,  0.7356],\n",
            "        [ 0.2335, -0.0481,  0.7434,  ..., -0.1977,  0.8662,  0.9425],\n",
            "        [ 0.2419,  0.0430,  0.5891,  ..., -0.1102,  0.7339,  0.6662]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:05,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159721a80>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db159720360>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1597205e0>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1597222a0>\n",
            " <function allInputsForMatrixProduct.<locals>.solution_generator at 0x7db1597232e0>]\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 13.163077\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 15.310668\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 13.009911\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 14.95765\n",
            "Nullspace component magnitude: 0.0\n",
            "Particular solution magnitude: 12.227378\n",
            "[array([-0.27576828,  0.25225067,  0.27639771, ...,  0.28079987,\n",
            "        0.07869816, -0.39780426]), array([-0.27689743,  0.31253052,  0.27256775, ...,  0.29450321,\n",
            "        0.10565758, -0.33648682]), array([-0.26398087,  0.24473572,  0.26526642, ...,  0.28561783,\n",
            "        0.08205128, -0.3875885 ]), array([-0.28074646,  0.26139069,  0.27772522, ...,  0.29389477,\n",
            "        0.07663727, -0.37230682]), array([-0.26522827,  0.22437286,  0.27134705, ...,  0.28248596,\n",
            "        0.08468342, -0.39128876])]\n",
            "torch.tensor(resultingAttentionOutputDenseInput): \n",
            "tensor([[-0.2758,  0.2523,  0.2764,  ...,  0.2808,  0.0787, -0.3978],\n",
            "        [-0.2769,  0.3125,  0.2726,  ...,  0.2945,  0.1057, -0.3365],\n",
            "        [-0.2640,  0.2447,  0.2653,  ...,  0.2856,  0.0821, -0.3876],\n",
            "        [-0.2807,  0.2614,  0.2777,  ...,  0.2939,  0.0766, -0.3723],\n",
            "        [-0.2652,  0.2244,  0.2713,  ...,  0.2825,  0.0847, -0.3913]],\n",
            "       dtype=torch.float64)\n",
            "intermediateOutputDenseInput[0]\n",
            "tensor([[-0.2757,  0.2522,  0.2764,  ...,  0.2808,  0.0787, -0.3979],\n",
            "        [-0.2768,  0.3125,  0.2725,  ...,  0.2945,  0.1057, -0.3365],\n",
            "        [-0.2640,  0.2448,  0.2652,  ...,  0.2856,  0.0821, -0.3875],\n",
            "        [-0.2808,  0.2613,  0.2777,  ...,  0.2939,  0.0767, -0.3722],\n",
            "        [-0.2653,  0.2244,  0.2714,  ...,  0.2825,  0.0847, -0.3912]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "intermediateOutputDenseInput = []\n",
        "intermediateOutputDenseOutput = []\n",
        "def hook_function(module, input, output):\n",
        "    global intermediateOutputDenseInput, intermediateOutputDenseOutput\n",
        "    print(\"Input:\", input[0]) # Accessing the input tensor\n",
        "    intermediateOutputDenseInput = input[0]\n",
        "    print(\"Output:\", output) # Accessing the output tensor\n",
        "    intermediateOutputDenseOutput = output\n",
        "\n",
        "hook = model.encoder.layer[23].attention.output.dense.register_forward_hook(hook_function)\n",
        "\n",
        "print(model.encoder.layer[23](outputs.hidden_states[23])[0][0][0])\n",
        "print(outputs.hidden_states[24][0][0])\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "print(intermediateOutputDenseInput[0])\n",
        "print(intermediateOutputDenseOutput[0])\n",
        "\n",
        "intemediateDenseNoBias = (intermediateOutputDenseOutput[0] - model.encoder.layer[23].attention.output.dense.bias).cpu().detach().clone().numpy()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "solutionGens = []\n",
        "for idx,i in tqdm(enumerate(intemediateDenseNoBias)):\n",
        "    solutionGens.append(allInputsForMatrixProduct(i, model.encoder.layer[23].attention.output.dense.weight.cpu().detach().clone().numpy()))\n",
        "\n",
        "solutionGens = np.array(solutionGens)\n",
        "print(solutionGens)\n",
        "\n",
        "dims = np.zeros(1024)\n",
        "resultingAttentionOutputDenseInput = [i(dims) for i in solutionGens]\n",
        "print(resultingAttentionOutputDenseInput)\n",
        "\n",
        "print(\"torch.tensor(resultingAttentionOutputDenseInput): \")\n",
        "print(torch.tensor(resultingAttentionOutputDenseInput))\n",
        "print(\"intermediateOutputDenseInput[0]\")\n",
        "print(intermediateOutputDenseInput[0])"
      ],
      "metadata": {
        "id": "tD_6URpwX0Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder.layer[23].attention.self.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUXJLYV8Xm-v",
        "outputId": "79d6acc8-e046-42c7-d4ae-cf762edb3aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBvef7RypO-1",
        "outputId": "96843cdc-2831-472e-8480-536f218f6bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 1024)\n",
            "    (token_type_embeddings): Embedding(2, 1024)\n",
            "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-23): 24 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "inputVectors = np.array([[1,2], [3,4], [5,6]])\n",
        "\n",
        "keyWeights = np.array([[0.5, -0.3, 0.6],\n",
        "                      [-0.2, 0.4, 0.5]])\n",
        "\n",
        "queryWeights = np.array([[0.4, 0.2, -0.5],\n",
        "                        [-0.3, 0.6, 0.4]])\n",
        "\n",
        "valueWeights = np.array([[0.5, -0.4, 0.3],\n",
        "                        [-0.2, 0.5, 0.4]])\n",
        "\n",
        "keys = inputVectors @ keyWeights\n",
        "queries = inputVectors @ queryWeights\n",
        "values = inputVectors @ valueWeights"
      ],
      "metadata": {
        "id": "K9DeWt-HrXNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attentionScores = keys @ queries.T\n",
        "attentionScores = attentionScores * 1/np.sqrt(3)\n",
        "attentionScores = np.exp(attentionScores) / np.sum(np.exp(attentionScores), axis=1, keepdims=True)\n",
        "\n",
        "attentionScores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1focvYJytL7T",
        "outputId": "ab588673-a35d-47f7-d235-644f5718a3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24295608, 0.32426329, 0.43278062],\n",
              "       [0.24295608, 0.32426329, 0.43278062],\n",
              "       [0.24295608, 0.32426329, 0.43278062]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newVectors = attentionScores @ values\n",
        "newVectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkbbbUjqwTQ1",
        "outputId": "e9c8bc7b-20e7-4af5-b3bc-add03b8d5e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81389473, 0.83796491, 2.76575436],\n",
              "       [0.81389473, 0.83796491, 2.76575436],\n",
              "       [0.81389473, 0.83796491, 2.76575436]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}